<!DOCTYPE html><html><head>
      <title>project1_openai_gym_taxi_v2</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////Users/abakh005/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.6.7/node_modules/@shd101wyy/mume/dependencies/katex/katex.min.css">
      
      
      
      
      
      
      
      
      
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p,html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div{display:inline}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  300px/2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      <h1 class="mume-header" id="-introduction">Introduction</h1>

<p><img src="https://video.udacity-data.com/topher/2018/April/5ad260ed_screen-shot-2018-04-14-at-3.13.15-pm/screen-shot-2018-04-14-at-3.13.15-pm.png" alt></p>
<h1 class="mume-header" id="-introduction-1">Introduction</h1>

<p>For this coding exercise, you will use OpenAI Gym&apos;s  <code>Taxi-v2</code>  environment to design an algorithm to teach a taxi agent to navigate a small gridworld. The goal is to adapt all that you&apos;ve learned in the previous lessons to solve a new environment!</p>
<p>Before proceeding, read the description of the environment in subsection 3.1 of  <a href="https://arxiv.org/pdf/cs/9905014.pdf">this paper</a>.</p>
<p>You can verify that the description in the paper matches the OpenAI Gym environment by peeking at the code  <a href="https://github.com/openai/gym/blob/master/gym/envs/toy_text/taxi.py">here</a>.</p>
<h1 class="mume-header" id="-instructions">Instructions</h1>

<p>Open the workspace in the next concept in a new window.</p>
<p><img src="https://video.udacity-data.com/topher/2018/July/5b3bb055_new-tab/new-tab.gif" alt="Open the workspace in a new window."></p>
<p>Open the workspace in a new window.</p>
<p>Next, open a terminal by clicking on  <strong>NEW TERMINAL</strong>. You will notice some output as the environment is configured.</p>
<p><img src="https://video.udacity-data.com/topher/2018/January/5a556990_open-terminal/open-terminal.gif" alt></p>
<p>Open a new terminal.</p>
<p>The workspace contains three files:</p>
<ul>
<li><code>agent.py</code>: Develop your reinforcement learning agent here. This is the only file that you should modify.</li>
<li><code>monitor.py</code>: The  <code>interact</code>  function tests how well your agent learns from interaction with the environment.</li>
<li><code>main.py</code>: Run this file in the terminal to check the performance of your agent.</li>
</ul>
<p>Open all three of these files in the workspace.</p>
<p><img src="https://video.udacity-data.com/topher/2018/January/5a5569ce_open-agent-monitor-main/open-agent-monitor-main.gif" alt></p>
<p>Open  <code>agent.py</code>,  <code>Monitor.py</code>, and  <code>main.py</code>.</p>
<p>Next, run  <code>main.py</code>  by executing  <code>python main.py</code>  in the terminal.</p>
<p><img src="https://video.udacity-data.com/topher/2018/January/5a556a14_run-main/run-main.gif" alt></p>
<p>Run  <code>python main.py</code>  in the terminal.</p>
<p>When you run  <code>main.py</code>, the agent that you specify in  <code>agent.py</code>  interacts with the environment for 20,000 episodes. The details of the interaction are specified in  <code>monitor.py</code>, which returns two variables:  <code>avg_rewards</code>  and  <code>best_avg_reward</code>.</p>
<ul>
<li><code>avg_rewards</code>  is a deque where  <code>avg_rewards[i]</code>  is the average (undiscounted) return collected by the agent from episodes  <code>i+1</code>  to episode  <code>i+100</code>, inclusive. So, for instance,  <code>avg_rewards[0]</code>  is the average return collected by the agent over the first 100 episodes.</li>
<li><code>best_avg_reward</code>  is the largest entry in  <code>avg_rewards</code>. This is the final score that you should use when determining how well your agent performed in the task.</li>
</ul>
<p>Your assignment is to modify the  <code>agents.py</code>  file to improve the agent&apos;s performance.</p>
<ul>
<li>Use the  <code>__init__()</code>  method to define any needed instance variables. Currently, we define the number of actions available to the agent (<code>nA</code>) and initialize the action values (<code>Q</code>) to an empty dictionary of arrays. Feel free to add more instance variables; for example, you may find it useful to define the value of epsilon if the agent uses an epsilon-greedy policy for selecting actions.</li>
<li>The  <code>select_action()</code>  method accepts the environment state as input and returns the agent&apos;s choice of action. The default code that we have provided randomly selects an action.</li>
<li>The  <code>step()</code>  method accepts a (<code>state</code>,  <code>action</code>,  <code>reward</code>,  <code>next_state</code>) tuple as input, along with the  <code>done</code>  variable, which is  <code>True</code>  if the episode has ended. The default code (which you should certainly change!) increments the action value of the previous state-action pair by 1. You should change this method to use the sampled tuple of experience to update the agent&apos;s knowledge of the problem.</li>
</ul>
<p>Once you have modified the function, you need only run  <code>python main.py</code>  to test your new agent.</p>
<p>While you are welcome to implement any algorithm of your choosing, note that it is possible to achieve satisfactory performance using some of the approaches that we have covered in the lessons.</p>
<h3 class="mume-header" id="-evaluate-your-performance">Evaluate your Performance</h3>

<hr>
<p>OpenAI Gym  <a href="https://gym.openai.com/envs/Taxi-v1/">defines &quot;solving&quot;</a>  this task as getting average return of 9.7 over 100 consecutive trials.</p>
<p>While this coding exercise is ungraded, we recommend that you try to attain an average return of at least 9.1 over 100 consecutive trials (<code>best_avg_reward</code>  &gt; 9.1).</p>
<h3 class="mume-header" id="-not-sure-where-to-start">Not sure where to start?</h3>

<hr>
<p><em>Note that this exercise is intentionally open-ended, and we won&apos;t provide an official solution</em>. For help with this exercise, please reach out to your instructors and fellow students! As a first step, you should figure out how to adapt your implementation in the  <strong>Temporal-Difference Methods</strong>  lesson to implement an agent to learn in this new environment. The code will likely be very similar to the notebook from the  <strong>Temporal-Difference Methods</strong>  lesson, where you need only modify very few things to fit this slightly different format.</p>
<h3 class="mume-header" id="-share-your-results">Share your Results</h3>

<hr>
<p>If you arrive at an implementation that you are proud of, please share your results with the student community! You can also reach out to ask questions, get implementation hints, share ideas, or find collaborators!</p>
<p>As a final step, towards sharing your ideas with the wider RL community, you may like to create a write-up and submit it to the  <a href="https://github.com/openai/gym/wiki/Leaderboard">OpenAI Gym Leaderboard</a>!</p>
<h1 class="mume-header" id="-mini-project">Mini Project</h1>

<p>Copied the codes from the Udacity workspace.</p>
<pre data-role="codeBlock" data-info="py" class="language-python"><span class="token comment"># agent.py</span>
<span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np
<span class="token keyword keyword-from">from</span> collections <span class="token keyword keyword-import">import</span> defaultdict

<span class="token keyword keyword-class">class</span> <span class="token class-name">Agent</span><span class="token punctuation">:</span>

    <span class="token keyword keyword-def">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nA<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot; Initialize agent.

        Params
        ======
        - nA: number of actions available to the agent
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>nA <span class="token operator">=</span> nA
        self<span class="token punctuation">.</span>Q <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token keyword keyword-lambda">lambda</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>nA<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword keyword-def">def</span> <span class="token function">select_action</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot; Given the state, select an action.

        Params
        ======
        - state: the current state of the environment

        Returns
        =======
        - action: an integer, compatible with the task&apos;s action space
        &quot;&quot;&quot;</span>
        <span class="token keyword keyword-return">return</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>self<span class="token punctuation">.</span>nA<span class="token punctuation">)</span>

    <span class="token keyword keyword-def">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> state<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_state<span class="token punctuation">,</span> done<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot; Update the agent&apos;s knowledge, using the most recently sampled tuple.

        Params
        ======
        - state: the previous state of the environment
        - action: the agent&apos;s previous choice of action
        - reward: last reward received
        - next_state: the current state of the environment
        - done: whether the episode is complete (True or False)
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>Q<span class="token punctuation">[</span>state<span class="token punctuation">]</span><span class="token punctuation">[</span>action<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>
</pre><pre data-role="codeBlock" data-info="py" class="language-python"><span class="token comment"># main.py</span>
<span class="token keyword keyword-from">from</span> agent <span class="token keyword keyword-import">import</span> Agent
<span class="token keyword keyword-from">from</span> monitor <span class="token keyword keyword-import">import</span> interact
<span class="token keyword keyword-import">import</span> gym
<span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np

env <span class="token operator">=</span> gym<span class="token punctuation">.</span>make<span class="token punctuation">(</span><span class="token string">&apos;Taxi-v2&apos;</span><span class="token punctuation">)</span>
agent <span class="token operator">=</span> Agent<span class="token punctuation">(</span><span class="token punctuation">)</span>
avg_rewards<span class="token punctuation">,</span> best_avg_reward <span class="token operator">=</span> interact<span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">)</span>
</pre><pre data-role="codeBlock" data-info="py" class="language-python"><span class="token comment"># monitor.py</span>
<span class="token keyword keyword-from">from</span> collections <span class="token keyword keyword-import">import</span> deque
<span class="token keyword keyword-import">import</span> sys
<span class="token keyword keyword-import">import</span> math
<span class="token keyword keyword-import">import</span> numpy <span class="token keyword keyword-as">as</span> np

<span class="token keyword keyword-def">def</span> <span class="token function">interact</span><span class="token punctuation">(</span>env<span class="token punctuation">,</span> agent<span class="token punctuation">,</span> num_episodes<span class="token operator">=</span><span class="token number">20000</span><span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&quot;&quot;&quot; Monitor agent&apos;s performance.
    
    Params
    ======
    - env: instance of OpenAI Gym&apos;s Taxi-v1 environment
    - agent: instance of class Agent (see Agent.py for details)
    - num_episodes: number of episodes of agent-environment interaction
    - window: number of episodes to consider when calculating average rewards

    Returns
    =======
    - avg_rewards: deque containing average rewards
    - best_avg_reward: largest value in the avg_rewards deque
    &quot;&quot;&quot;</span>
    <span class="token comment"># initialize average rewards</span>
    avg_rewards <span class="token operator">=</span> deque<span class="token punctuation">(</span>maxlen<span class="token operator">=</span>num_episodes<span class="token punctuation">)</span>
    <span class="token comment"># initialize best average reward</span>
    best_avg_reward <span class="token operator">=</span> <span class="token operator">-</span>math<span class="token punctuation">.</span>inf
    <span class="token comment"># initialize monitor for most recent rewards</span>
    samp_rewards <span class="token operator">=</span> deque<span class="token punctuation">(</span>maxlen<span class="token operator">=</span>window<span class="token punctuation">)</span>
    <span class="token comment"># for each episode</span>
    <span class="token keyword keyword-for">for</span> i_episode <span class="token keyword keyword-in">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_episodes<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># begin the episode</span>
        state <span class="token operator">=</span> env<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># initialize the sampled reward</span>
        samp_reward <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword keyword-while">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
            <span class="token comment"># agent selects an action</span>
            action <span class="token operator">=</span> agent<span class="token punctuation">.</span>select_action<span class="token punctuation">(</span>state<span class="token punctuation">)</span>
            <span class="token comment"># agent performs the selected action</span>
            next_state<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> done<span class="token punctuation">,</span> _ <span class="token operator">=</span> env<span class="token punctuation">.</span>step<span class="token punctuation">(</span>action<span class="token punctuation">)</span>
            <span class="token comment"># agent performs internal updates based on sampled experience</span>
            agent<span class="token punctuation">.</span>step<span class="token punctuation">(</span>state<span class="token punctuation">,</span> action<span class="token punctuation">,</span> reward<span class="token punctuation">,</span> next_state<span class="token punctuation">,</span> done<span class="token punctuation">)</span>
            <span class="token comment"># update the sampled reward</span>
            samp_reward <span class="token operator">+=</span> reward
            <span class="token comment"># update the state (s &lt;- s&apos;) to next time step</span>
            state <span class="token operator">=</span> next_state
            <span class="token keyword keyword-if">if</span> done<span class="token punctuation">:</span>
                <span class="token comment"># save final sampled reward</span>
                samp_rewards<span class="token punctuation">.</span>append<span class="token punctuation">(</span>samp_reward<span class="token punctuation">)</span>
                <span class="token keyword keyword-break">break</span>
        <span class="token keyword keyword-if">if</span> <span class="token punctuation">(</span>i_episode <span class="token operator">&gt;=</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># get average reward from last 100 episodes</span>
            avg_reward <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>samp_rewards<span class="token punctuation">)</span>
            <span class="token comment"># append to deque</span>
            avg_rewards<span class="token punctuation">.</span>append<span class="token punctuation">(</span>avg_reward<span class="token punctuation">)</span>
            <span class="token comment"># update best average reward</span>
            <span class="token keyword keyword-if">if</span> avg_reward <span class="token operator">&gt;</span> best_avg_reward<span class="token punctuation">:</span>
                best_avg_reward <span class="token operator">=</span> avg_reward
        <span class="token comment"># monitor progress</span>
        <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">&quot;\rEpisode {}/{} || Best average reward {}&quot;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i_episode<span class="token punctuation">,</span> num_episodes<span class="token punctuation">,</span> best_avg_reward<span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">&quot;&quot;</span><span class="token punctuation">)</span>
        sys<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># check if task is solved (according to OpenAI Gym)</span>
        <span class="token keyword keyword-if">if</span> best_avg_reward <span class="token operator">&gt;=</span> <span class="token number">9.7</span><span class="token punctuation">:</span>
            <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">&apos;\nEnvironment solved in {} episodes.&apos;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i_episode<span class="token punctuation">)</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">&quot;&quot;</span><span class="token punctuation">)</span>
            <span class="token keyword keyword-break">break</span>
        <span class="token keyword keyword-if">if</span> i_episode <span class="token operator">==</span> num_episodes<span class="token punctuation">:</span> <span class="token keyword keyword-print">print</span><span class="token punctuation">(</span><span class="token string">&apos;\n&apos;</span><span class="token punctuation">)</span>
    <span class="token keyword keyword-return">return</span> avg_rewards<span class="token punctuation">,</span> best_avg_reward
</pre>
      </div>
      
      
    
    
    
    
    
    
    
    
  
    </body></html>