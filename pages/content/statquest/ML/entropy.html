<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>entropy.md</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
<style>
/* Style the button that is used to open and close the collapsible content */
.collapsible {
  background-color: #eee;
  color: #444;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
}

/* Add a background color to the button if it is clicked on (add the .active class with JS), and when you move the mouse over it (hover) */
.active, .collapsible:hover {
  background-color: #ccc;
}

/* Style the collapsible content. Note: hidden by default */
.content {
  padding: 0 18px;
  display: none;
  overflow: hidden;
  background-color: #f1f1f1;
}
</style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
</head>

<body class="stackedit">
  <div class="stackedit__left">
    <div class="stackedit__toc">
      
<ul>
<li><a href="#introduction">Introduction</a>
<ul>
<li></li>
</ul>
</li>
</ul>

    </div>
  </div>
  <div class="stackedit__right">
    <div class="stackedit__html">
      <h1 id="introduction">Introduction</h1>
<p>Entropy is used for a lot of things in data science. For example, entropy can be used to build classification trees. Entropy is also the basis of something called <strong>Mutual Information</strong>, which quantifies the relationship between two things. Entropy is the basis of <strong>Relative Entropy</strong> (also known as <strong>The Kullback-Leibler Distance</strong>) and <strong>cross entropy</strong>, which show up all over the place, including fancy dimension reduction algorithms like <strong>t-SNE</strong> and <strong>UMAP</strong>.</p>
<p>What these three things have in common is that they all use <strong>entropy</strong>, or something derived from it, to quantify <strong>similarities</strong> and <strong>differences</strong>.</p>
<p>In order to talk about <strong>Entropy</strong>, first we have to understand <strong>Surprise</strong>.</p>
<p>Imagine we have two types of chickens, <em>orange</em> and <em>blue</em>. Instead of just letting them randomly roam all over the screen, say, we organize them into three separate areas, <strong>A, B,</strong> and <strong>C.</strong></p>
<p><a href="https://www.flickr.com/photos/192167571@N04/51756337957/in/dateposted-friend/" title="Screen Shot 2021-12-19 at 1.28.11 PM"><img src="https://live.staticflickr.com/65535/51756337957_e9636b67a2_c.jpg" width="70%" height="auto" alt="Screen Shot 2021-12-19 at 1.28.11 PM"></a></p>
<p><a href="https://www.flickr.com/photos/192167571@N04/51756337937/in/dateposted-friend/" title="Screen Shot 2021-12-19 at 1.29.03 PM"><img src="https://live.staticflickr.com/65535/51756337937_d11eeb00b7_c.jpg" width="200" height="50%" alt="Screen Shot 2021-12-19 at 1.29.03 PM"></a></p>
<p>Now, if you randomly pick up a chicken from <strong>A</strong>, because there are more <em>orange</em> chickens, it’s more likely to pick <em>orange</em> over <em>blue</em>, thus, it’d <em>not be very surprising</em> to pick an <em>orange</em> chicken. In contrast, it’d be relatively surprising if a blue chicken is picked up. Similar opposite situation for the area <strong>B</strong>. Area <strong>C</strong> has equal number of orange and blue chickens. Thus, regardless of what color of chicken we pick up, we’d be equally surprised.</p>
<p><em><strong>Surprise is, in some way, inversely related to probability.</strong></em> In other words, when the <strong>probability</strong> is <strong>low</strong>, the <strong>surprise</strong> is <strong>high</strong> and visa versa.</p>
<h3 id="lets-see-how-to-quantify-surprise">Let’s see how to quantify surprise?</h3>
<p>Because we know there is a type of inverse relationship between probability and surprise, it’s tempting to just use the inverse of probability to calculate surprise,</p>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>surprise</mtext><mo>=</mo><mfrac><mn>1</mn><mstyle mathsize="0.9em"><mtext>probability</mtext></mstyle></mfrac></mrow><annotation encoding="application/x-tex">\text{surprise}=\frac{1}{\small{\text{probability}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8623em; vertical-align: -0.19444em;"></span><span class="mord text"><span class="mord">surprise</span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.4551em; vertical-align: -0.609992em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.845108em;"><span class="" style="top: -2.565em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sizing reset-size3 size5"><span class="mord text"><span class="mord">probability</span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.609992em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>There’s at least one <strong>problem</strong> with just using the inverse of of the probability to calculate surprise. Let’s examine this problem through an example fo surprise in flipping a coin.</p>
<ul>
<li>Imagine we had a terrible coin that always come up <em>heads</em>, i.e. <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>prob(heads)&nbsp;=&nbsp;1</mtext></mrow><annotation encoding="application/x-tex">\text{prob(heads) = 1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">prob(heads)&nbsp;=&nbsp;1</span></span></span></span></span></span>. That means coming heads is no surprise. Now, if we take the inverse of that, it’ll be also <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span></span></span></span></span>, whereas we expected surprise to be <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0</span></span></span></span></span>.</li>
<li>Now, if instead of inverse we use the log of inverse, then we’ll get <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0</span></span></span></span></span> for such cases.</li>
</ul>
<p><em><strong>Surprise is the log of the inverse of the probability.</strong></em></p>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>surprise</mtext><mo>=</mo><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><mfrac><mn>1</mn><mstyle mathsize="0.9em"><mtext>probability</mtext></mstyle></mfrac><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{surprise}=\log{(\frac{1}{\small{\text{probability}}})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.8623em; vertical-align: -0.19444em;"></span><span class="mord text"><span class="mord">surprise</span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.4551em; vertical-align: -0.609992em;"></span><span class="mop">lo<span style="margin-right: 0.01389em;">g</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.845108em;"><span class="" style="top: -2.565em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sizing reset-size3 size5"><span class="mord text"><span class="mord">probability</span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.609992em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></span></p>
<p><strong>Note:</strong> When calculating surprise for <strong>2</strong> outputs, it is customary to use the <strong>log base 2</strong> for the calculations.</p>
<p><strong>Note:</strong> For calculating the suprise of multiple events, we just need to add up their individual surprises. For instance, the surprise for getting 2 heads and 1 tails in 3 coin flips is the <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>surprise(heads)&nbsp;+&nbsp;surprise(heads)&nbsp;+&nbsp;surprise(tails)</mtext></mrow><annotation encoding="application/x-tex">\text{surprise(heads) + surprise(heads) + surprise(tails)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord">surprise(heads)&nbsp;+&nbsp;surprise(heads)&nbsp;+&nbsp;surprise(tails)</span></span></span></span></span></span>.</p>
<p>Now, let’s say we have coin with <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathsize="0.9em"><mrow><mtext mathvariant="bold">prob(heads)=0.9</mtext><mtext>&nbsp;</mtext><mtext mathvariant="bold">and</mtext><mtext>&nbsp;</mtext><mtext mathvariant="bold">prob(tails)=0.1</mtext></mrow></mstyle></mrow><annotation encoding="application/x-tex">\small{\textbf{prob(heads)=0.9 and prob(tails)=0.1}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9em; vertical-align: -0.225em;"></span><span class="mord sizing reset-size6 size5"><span class="mord text"><span class="mord textbf">prob(heads)=0.9&nbsp;and&nbsp;prob(tails)=0.1</span></span></span></span></span></span></span>.</p>

<table>
<thead>
<tr>
<th></th>
<th>Heads</th>
<th>Tails</th>
</tr>
</thead>
<tbody>
<tr>
<td><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathsize="0.9em"><mtext>probability:&nbsp;p(x)</mtext></mstyle></mrow><annotation encoding="application/x-tex">\text{\small{probability:} p(x)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.9em; vertical-align: -0.225em;"></span><span class="mord text"><span class="mord sizing reset-size6 size5"><span class="mord">probability:</span></span><span class="mord sizing reset-size6 size5">&nbsp;p(x)</span></span></span></span></span></span></td>
<td>0.9</td>
<td>0.1</td>
</tr>
<tr>
<td><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathsize="0.9em"><mtext>surprise:</mtext></mstyle><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mfrac><mn>1</mn><mi>p</mi></mfrac></mrow><annotation encoding="application/x-tex">\text{\small{surprise:}} \log_2 {\frac{1}{p}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1.32622em; vertical-align: -0.481108em;"></span><span class="mord text"><span class="mord sizing reset-size6 size5"><span class="mord">surprise:</span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop"><span class="mop">lo<span style="margin-right: 0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.206968em;"><span class="" style="top: -2.45586em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.24414em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.845108em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.481108em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></td>
<td>0.15</td>
<td>3.32</td>
</tr>
</tbody>
</table><p><em><strong>How do we estimate the total surprise after flipping the coin 100 times?</strong></em></p>
<ul>
<li>We approximate how many times we will get <em>heads</em> by multiplying its probability by 100,</li>
<li>We estimate the total surprise from getting 100 <em>heads</em> by multiplying it by <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.15</mn></mrow><annotation encoding="application/x-tex">0.15</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0.15</span></span></span></span></span>.</li>
</ul>
<p>Likewise, we can get the estimate from getting 100 <em>tails</em>.</p>
<center><a href="https://www.flickr.com/photos/192167571@N04/51776356905/in/dateposted-friend/" title="Screen Shot 2021-12-25 at 8.12.01 PM"><img src="https://live.staticflickr.com/65535/51776356905_8433c01709_c.jpg" width="70%" height="auto" alt="Screen Shot 2021-12-25 at 8.12.01 PM"></a></center>
<p>If we divide everything by the number of coin tosses, we get average amount of surprise per coin toss,</p>
<center><a href="https://www.flickr.com/photos/192167571@N04/51776116594/in/dateposted-friend/" title="Screen Shot 2021-12-25 at 8.14.43 PM"><img src="https://live.staticflickr.com/65535/51776116594_510a6176a5_c.jpg" width="70%" height="auto" alt="Screen Shot 2021-12-25 at 8.14.43 PM"></a></center>
<p>This average suprise is the <strong>entropy</strong> of the coin, i.e. the expected surprise every time we flip the coin.</p>
<p><em><strong>Entropy is the expected value of surprise.</strong></em></p>
<p><strong>Note:</strong> Number of coin toss really doesn’t matter here, since it gets cancelled out.</p>
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Entropy</mtext><mo>=</mo><mo>∑</mo><mi>x</mi><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Entropy} = \sum x P(X=x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord text"><span class="mord">Entropy</span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.60001em; vertical-align: -0.55001em;"></span><span class="mop op-symbol large-op" style="position: relative; top: -5e-06em;">∑</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathnormal">x</span><span class="mord mathnormal" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.07847em;">X</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></span></p>
<p>Where,</p>
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>→</mo><mtext>specific&nbsp;value&nbsp;for&nbsp;</mtext><mtext mathvariant="bold">surprise</mtext><mo>→</mo><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mfrac><mn>1</mn><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">x \rightarrow \text{specific value for }\textbf{surprise} \rightarrow \log_2 \frac{1}{p(x)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord text"><span class="mord">specific&nbsp;value&nbsp;for&nbsp;</span></span><span class="mord text"><span class="mord textbf">surprise</span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.36511em; vertical-align: -0.52em;"></span><span class="mop"><span class="mop">lo<span style="margin-right: 0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.206968em;"><span class="" style="top: -2.45586em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.24414em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.845108em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.52em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><br>
<span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo stretchy="false">)</mo><mo>→</mo><mtext>the&nbsp;probability&nbsp;of&nbsp;observing&nbsp;that&nbsp;specific&nbsp;value&nbsp;for&nbsp;</mtext><mtext mathvariant="bold">surprise</mtext><mo>→</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X=x) \rightarrow \text{the probability of observing that specific value for }\textbf{surprise} \rightarrow p(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.07847em;">X</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord text"><span class="mord">the&nbsp;probability&nbsp;of&nbsp;observing&nbsp;that&nbsp;specific&nbsp;value&nbsp;for&nbsp;</span></span><span class="mord text"><span class="mord textbf">surprise</span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></p>
<p>Therefore, the equation for <strong>entropy</strong> is</p>
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Entropy</mtext><mo>=</mo><mo>∑</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mfrac><mn>1</mn><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac><mo stretchy="false">)</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Entropy} = \sum \log(\frac{1}{p(x)}) p(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord text"><span class="mord">Entropy</span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.25744em; vertical-align: -0.936em;"></span><span class="mop op-symbol large-op" style="position: relative; top: -5e-06em;">∑</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop">lo<span style="margin-right: 0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></span></p>
<p><strong>Note:</strong> Unfortunately, even though this equation is made from two relatively easy to interpret terms, i.e. surprise <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.66666em; vertical-align: -0.08333em;"></span><span class="mord">×</span></span></span></span></span> prob(surprise), <em><strong>this isn’t the standard form of the equation for the entropy</strong></em>. The well-known equation is just the simplified version of it,</p>
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Entropy</mtext><mo>=</mo><mo>−</mo><mo>∑</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Entropy} = -\sum p(x)\log(p(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord text"><span class="mord">Entropy</span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.60001em; vertical-align: -0.55001em;"></span><span class="mord">−</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop op-symbol large-op" style="position: relative; top: -5e-06em;">∑</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop">lo<span style="margin-right: 0.01389em;">g</span></span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span></span></span></span></span></span></p>
<p>This is entropy equation that <strong>Claude Shannon</strong> first published in <strong>1948</strong>.</p>
<p>Now, going back to our chicken example, if we calculate the entropy for A, B, and C, we’ll see that entropy is highest when we have the same number of both types of chickens, and as we increase the difference in the number of orange and blue chickens, we lower the entropy.</p>

    </div>
  </div>
  <script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
</script>
<script src="https://gist.github.com/username/a39a422ebdff6e732753b90573100b16.js"></script>
</body>

</html>
